{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":10102104,"sourceType":"datasetVersion","datasetId":6230946}],"dockerImageVersionId":30805,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"pip install torch torchvision timm pandas requests","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-12-12T19:00:20.552050Z","iopub.status.idle":"2024-12-12T19:00:20.552358Z","shell.execute_reply.started":"2024-12-12T19:00:20.552201Z","shell.execute_reply":"2024-12-12T19:00:20.552216Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from PIL import Image\nimport torch\nimport timm\nimport requests\nimport torchvision.transforms as transforms\nfrom timm.data.constants import IMAGENET_DEFAULT_MEAN, IMAGENET_DEFAULT_STD\n\nprint(torch.__version__)\n# # should be 1.8.0\n\n\n# model = torch.hub.load('facebookresearch/deit:main', 'deit_base_patch16_224', pretrained=True)\n# model.eval()\n\n# transform = transforms.Compose([\n#     transforms.Resize(256, interpolation=3),\n#     transforms.CenterCrop(224),\n#     transforms.ToTensor(),\n#     transforms.Normalize(IMAGENET_DEFAULT_MEAN, IMAGENET_DEFAULT_STD),\n# ])\n\n# img = Image.open(requests.get(\"https://raw.githubusercontent.com/pytorch/ios-demo-app/master/HelloWorld/HelloWorld/HelloWorld/image.png\", stream=True).raw)\n# img = transform(img)[None,]\n# out = model(img)\n# clsidx = torch.argmax(out)\n# print(clsidx.item())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-12T19:01:18.473204Z","iopub.execute_input":"2024-12-12T19:01:18.473548Z","iopub.status.idle":"2024-12-12T19:01:28.058863Z","shell.execute_reply.started":"2024-12-12T19:01:18.473517Z","shell.execute_reply":"2024-12-12T19:01:28.057924Z"}},"outputs":[{"name":"stdout","text":"2.4.0\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"# model = torch.hub.load('facebookresearch/deit:main', 'deit_base_patch16_224', pretrained=True)\n# model.eval()\n# scripted_model = torch.jit.script(model)\n# scripted_model.save(\"fbdeit_scripted.pt\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-04T20:27:34.936667Z","iopub.execute_input":"2024-12-04T20:27:34.937443Z","iopub.status.idle":"2024-12-04T20:27:34.940772Z","shell.execute_reply.started":"2024-12-04T20:27:34.937410Z","shell.execute_reply":"2024-12-04T20:27:34.939870Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# # Use 'x86' for server inference (the old 'fbgemm' is still available but 'x86' is the recommended default) and ``qnnpack`` for mobile inference.\n# backend = \"x86\" # replaced with ``qnnpack`` causing much worse inference speed for quantized model on this notebook\n# model.qconfig = torch.quantization.get_default_qconfig(backend)\n# torch.backends.quantized.engine = backend\n\n# quantized_model = torch.quantization.quantize_dynamic(model, qconfig_spec={torch.nn.Linear}, dtype=torch.qint8)\n# scripted_quantized_model = torch.jit.script(quantized_model)\n# scripted_quantized_model.save(\"fbdeit_scripted_quantized.pt\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-04T20:27:38.459762Z","iopub.execute_input":"2024-12-04T20:27:38.460431Z","iopub.status.idle":"2024-12-04T20:27:38.464119Z","shell.execute_reply.started":"2024-12-04T20:27:38.460400Z","shell.execute_reply":"2024-12-04T20:27:38.463209Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# out = scripted_quantized_model(img)\n# clsidx = torch.argmax(out)\n# print(clsidx.item())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-04T20:27:41.402350Z","iopub.execute_input":"2024-12-04T20:27:41.402657Z","iopub.status.idle":"2024-12-04T20:27:41.406350Z","shell.execute_reply.started":"2024-12-04T20:27:41.402624Z","shell.execute_reply":"2024-12-04T20:27:41.405542Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# from torch.utils.mobile_optimizer import optimize_for_mobile\n# optimized_scripted_quantized_model = optimize_for_mobile(scripted_quantized_model)\n# optimized_scripted_quantized_model.save(\"fbdeit_optimized_scripted_quantized.pt\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-04T20:27:49.074207Z","iopub.execute_input":"2024-12-04T20:27:49.074545Z","iopub.status.idle":"2024-12-04T20:27:49.078536Z","shell.execute_reply.started":"2024-12-04T20:27:49.074517Z","shell.execute_reply":"2024-12-04T20:27:49.077696Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# out = optimized_scripted_quantized_model(img)\n# clsidx = torch.argmax(out)\n# print(clsidx.item())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-04T20:27:51.346290Z","iopub.execute_input":"2024-12-04T20:27:51.346629Z","iopub.status.idle":"2024-12-04T20:27:51.350336Z","shell.execute_reply.started":"2024-12-04T20:27:51.346601Z","shell.execute_reply":"2024-12-04T20:27:51.349438Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# optimized_scripted_quantized_model._save_for_lite_interpreter(\"fbdeit_optimized_scripted_quantized_lite.ptl\")\n# ptl = torch.jit.load(\"fbdeit_optimized_scripted_quantized_lite.ptl\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-04T20:27:54.110498Z","iopub.execute_input":"2024-12-04T20:27:54.110824Z","iopub.status.idle":"2024-12-04T20:27:54.114716Z","shell.execute_reply.started":"2024-12-04T20:27:54.110795Z","shell.execute_reply":"2024-12-04T20:27:54.113802Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# with torch.autograd.profiler.profile(use_cuda=False) as prof1:\n#     out = model(img)\n# with torch.autograd.profiler.profile(use_cuda=False) as prof2:\n#     out = scripted_model(img)\n# with torch.autograd.profiler.profile(use_cuda=False) as prof3:\n#     out = scripted_quantized_model(img)\n# with torch.autograd.profiler.profile(use_cuda=False) as prof4:\n#     out = optimized_scripted_quantized_model(img)\n# with torch.autograd.profiler.profile(use_cuda=False) as prof5:\n#     out = ptl(img)\n\n# print(\"original model: {:.2f}ms\".format(prof1.self_cpu_time_total/1000))\n# print(\"scripted model: {:.2f}ms\".format(prof2.self_cpu_time_total/1000))\n# print(\"scripted & quantized model: {:.2f}ms\".format(prof3.self_cpu_time_total/1000))\n# print(\"scripted & quantized & optimized model: {:.2f}ms\".format(prof4.self_cpu_time_total/1000))\n# print(\"lite model: {:.2f}ms\".format(prof5.self_cpu_time_total/1000))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-04T20:28:03.239619Z","iopub.execute_input":"2024-12-04T20:28:03.240477Z","iopub.status.idle":"2024-12-04T20:28:03.244584Z","shell.execute_reply.started":"2024-12-04T20:28:03.240440Z","shell.execute_reply":"2024-12-04T20:28:03.243722Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Fine Tuning First...","metadata":{}},{"cell_type":"code","source":"import os\nimport zipfile\nimport cv2\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nimport torch\nimport torch.nn as nn\nrandom_seed=42\ntorch.manual_seed(random_seed)\nimport torch.optim as optim\nfrom torch.utils.data import Dataset,DataLoader\nfrom sklearn.metrics import accuracy_score\nnp.random.seed(random_seed)\n\nimport torch\nimport torch.optim as optim\nimport torch.nn.functional as F","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-12T19:02:18.424259Z","iopub.execute_input":"2024-12-12T19:02:18.424643Z","iopub.status.idle":"2024-12-12T19:02:19.792513Z","shell.execute_reply.started":"2024-12-12T19:02:18.424611Z","shell.execute_reply":"2024-12-12T19:02:19.791830Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"#@title \"Data Prep\"\nroot_path='/kaggle/input/kather2016/Kather_texture_2016_image_tiles_5000'\n#------------------------------------------------------------------------------------------------------------------------------------------------------------------\ntumors,stroma,complex,lympho,debris,mucosa,adipose,empty=[],[],[],[],[],[],[],[]\nfor index in range(8):\n  if index==0:\n    tumors=tumors+(os.listdir(root_path+'/01_TUMOR'))\n    tumors=[root_path+'/01_TUMOR/'+item for item in tumors]\n  elif index==1:\n    stroma+=(os.listdir(root_path+'/02_STROMA'))\n    stroma=[root_path+'/02_STROMA/'+item for item in stroma]\n  elif index==2:\n    complex+=(os.listdir(root_path+'/03_COMPLEX'))\n    complex=[root_path+'/03_COMPLEX/'+item for item in complex]\n  elif index==3:\n    lympho+=(os.listdir(root_path+'/04_LYMPHO'))\n    lympho=[root_path+'/04_LYMPHO/'+item for item in lympho]\n  elif index==4:\n    debris+=(os.listdir(root_path+'/05_DEBRIS'))\n    debris=[root_path+'/05_DEBRIS/'+item for item in debris]\n  elif index==5:\n    mucosa+=(os.listdir(root_path+'/06_MUCOSA'))\n    mucosa=[root_path+'/06_MUCOSA/'+item for item in mucosa]\n  elif index==6:\n    adipose+=(os.listdir(root_path+'/07_ADIPOSE'))\n    adipose=[root_path+'/07_ADIPOSE/'+item for item in adipose]\n  else:\n    empty+=(os.listdir(root_path+'/08_EMPTY'))\n    empty=[root_path+'/08_EMPTY/'+item for item in empty]\n      \nprint('Tumors {}\\nStroma {}\\nComplex {}\\nLympho {}\\nDebris {}\\n Mucosa {}\\n Adipose {}\\n Empty {}'.format(len(tumors),len(stroma),len(complex),len(lympho),len(debris),len(mucosa),len(adipose),len(empty)))\n\n#------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n#Creating dataframe\nall_files=tumors+stroma+complex+lympho+debris+mucosa+adipose+empty\nlabels=[]\nfor _ in range(len(tumors)):\n  # labels.append(1)\n  labels.append('tumor')\nfor _ in range(len(stroma)):\n  # labels.append(2)\n  labels.append('stroma')\nfor _ in range(len(complex)):\n  # labels.append(3)\n  labels.append('complex')\nfor _ in range(len(lympho)):\n  # labels.append(4)\n  labels.append('lympho')\nfor _ in range(len(debris)):\n  # labels.append(5)\n  labels.append('debris')\nfor _ in range(len(mucosa)):\n  # labels.append(6)\n  labels.append('mucosa')\nfor _ in range(len(adipose)):\n  # labels.append(7)\n  labels.append('adipose')\nfor _ in range(len(empty)):\n  # labels.append(8)\n  labels.append('empty')\n\ntrain_df=pd.DataFrame({\n    \"Filename\":all_files,\n    \"Labels\":labels\n})\ntrain_df['Labels'] = train_df['Labels'].astype(str)\n\n#------------------------------------------------------------------------------------------------------------------------------------------------------------------\ntest_splits=[.9,.8,.75,.7,.65,.6]\n\nfor split in test_splits:\n    \n  train_df_,test_df_=train_test_split(train_df,test_size=split,random_state=random_seed,stratify=train_df['Labels'],shuffle=True)\n  test_df_,val_df_=train_test_split(test_df_,test_size=0.2,random_state=random_seed,stratify=test_df_['Labels'],shuffle=True)\n  test_df_.reset_index(drop=True,inplace=True)\n  train_df_.reset_index(drop=True,inplace=True)\n  val_df_.reset_index(drop=True,inplace=np.True_)\n    \n  train_df_.to_csv('Training_point{}.csv'.format(int(split*100)),index=False)\n  test_df_.to_csv('Test_point{}.csv'.format(int(split*100)),index=False)\n  val_df_.to_csv('Val_point{}.csv'.format(int(split*100)),index=False)\n    ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-12T19:02:21.109098Z","iopub.execute_input":"2024-12-12T19:02:21.109643Z","iopub.status.idle":"2024-12-12T19:02:21.949408Z","shell.execute_reply.started":"2024-12-12T19:02:21.109608Z","shell.execute_reply":"2024-12-12T19:02:21.948423Z"}},"outputs":[{"name":"stdout","text":"Tumors 625\nStroma 625\nComplex 625\nLympho 625\nDebris 625\n Mucosa 625\n Adipose 625\n Empty 625\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"#@title \"Load train,test,val\"\ndef read_csv(path:str):\n  df=pd.read_csv(path)\n  return df\n\ntrain_df=read_csv('Training_point90.csv')\ntest_df=read_csv('Test_point90.csv')\nval_df=read_csv('Val_point90.csv')\n\nlabels=sorted(list(train_df['Labels'].unique()))\n\nlabel2idx={}\nidx2label={}\n\nfor idx,label in enumerate(labels):\n  label2idx[label]=idx\n  idx2label[idx]=label\n\ntrain_df['Labels']=train_df['Labels'].map(label2idx)\ntest_df['Labels']=test_df['Labels'].map(label2idx)\nval_df['Labels']=val_df['Labels'].map(label2idx)\n\nprint(f''' \nTraining data: {train_df.shape[0]}\\n\nTest data : {test_df.shape[0]}\\n\nValidation data : {val_df.shape[0]}\n''')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-12T19:02:55.899477Z","iopub.execute_input":"2024-12-12T19:02:55.900357Z","iopub.status.idle":"2024-12-12T19:02:55.935483Z","shell.execute_reply.started":"2024-12-12T19:02:55.900319Z","shell.execute_reply":"2024-12-12T19:02:55.934583Z"}},"outputs":[{"name":"stdout","text":" \nTraining data: 500\n\nTest data : 3600\n\nValidation data : 900\n\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"teacher = torch.hub.load('facebookresearch/deit:main', 'deit_base_patch16_224', pretrained=True)\nstudent = torch.hub.load('facebookresearch/deit:main', 'deit_base_patch16_224', pretrained=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-12T19:02:32.975277Z","iopub.execute_input":"2024-12-12T19:02:32.975873Z","iopub.status.idle":"2024-12-12T19:02:36.493777Z","shell.execute_reply.started":"2024-12-12T19:02:32.975822Z","shell.execute_reply":"2024-12-12T19:02:36.492952Z"}},"outputs":[{"name":"stderr","text":"Using cache found in /root/.cache/torch/hub/facebookresearch_deit_main\nUsing cache found in /root/.cache/torch/hub/facebookresearch_deit_main\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"transform = transforms.Compose([\n    transforms.Resize(256, interpolation=3),\n    transforms.CenterCrop(224),\n    transforms.ToTensor(),\n    transforms.Normalize(IMAGENET_DEFAULT_MEAN, IMAGENET_DEFAULT_STD),\n])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-12T19:02:36.495075Z","iopub.execute_input":"2024-12-12T19:02:36.495358Z","iopub.status.idle":"2024-12-12T19:02:36.499848Z","shell.execute_reply.started":"2024-12-12T19:02:36.495326Z","shell.execute_reply":"2024-12-12T19:02:36.498898Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"class TissueData(Dataset):\n  @staticmethod\n  def read_img(path:str):\n    img=cv2.imread(path)\n    img=cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n    img=cv2.resize(img,(224,224))\n    img=img.astype(np.float32)\n    img=np.transpose(img,(2,0,1))\n    img=img/255.\n    return img\n  def __init__(self,df:pd.DataFrame):\n    self.df=df\n  def __len__(self):\n    return len(self.df)\n  def __getitem__(self,idx):\n    img_path=self.df.iloc[idx,0]\n    img=self.read_img(img_path)\n    label=int(self.df['Labels'][idx])\n    return img,label\n\n#@title \"Custom Dataset Unlabeled\"\nclass UnlabeledTissueData(Dataset):\n  @staticmethod\n  def read_img(path:str):\n    img=cv2.imread(path)\n    img=cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n    img=cv2.resize(img,(224,224))\n    img=img.astype(np.float32)\n    img=np.transpose(img,(2,0,1))\n    img=img/255.\n    return img\n      \n  def __init__(self,df:pd.DataFrame):\n    self.df=df\n  def __len__(self):\n    return len(self.df)\n  def __getitem__(self,idx):\n    img_path=self.df.iloc[idx,0]\n    img=self.read_img(img_path)\n    return img","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-12T19:02:59.532740Z","iopub.execute_input":"2024-12-12T19:02:59.533085Z","iopub.status.idle":"2024-12-12T19:02:59.542171Z","shell.execute_reply.started":"2024-12-12T19:02:59.533055Z","shell.execute_reply":"2024-12-12T19:02:59.541225Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"params={\n    'batch_size':16,\n    'shuffle':True,\n    'num_workers':4,\n    'pin_memory':True,\n    'epochs':20,\n    'lr':0.001,\n    'device':'cuda' if torch.cuda.is_available() else 'cpu'\n}\nlabeled_ds=TissueData(train_df)\nlabeled_loader=DataLoader(labeled_ds,batch_size=params['batch_size'],shuffle=True)\nval_ds=TissueData(val_df)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-12T19:03:00.766720Z","iopub.execute_input":"2024-12-12T19:03:00.767052Z","iopub.status.idle":"2024-12-12T19:03:00.772740Z","shell.execute_reply.started":"2024-12-12T19:03:00.767022Z","shell.execute_reply":"2024-12-12T19:03:00.771824Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"#Remove labels from test_df\nunlabelled_df=test_df.drop('Labels',axis=1)\nunlabelled_df=unlabelled_df.reset_index(drop=True)\nunlabeled_loader=DataLoader(UnlabeledTissueData(unlabelled_df),batch_size=params['batch_size'],shuffle=False)\nval_loader=DataLoader(val_ds,batch_size=params['batch_size'],shuffle=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-12T19:03:02.089632Z","iopub.execute_input":"2024-12-12T19:03:02.090515Z","iopub.status.idle":"2024-12-12T19:03:02.100892Z","shell.execute_reply.started":"2024-12-12T19:03:02.090464Z","shell.execute_reply":"2024-12-12T19:03:02.099975Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"num_epochs=params['epochs']\n# Optimizers\nt_optimizer = optim.SGD(teacher.parameters(), lr=0.001,momentum=0.9)\ns_optimizer = optim.SGD(student.parameters(), lr=0.001,momentum=0.9)\n\n# Lists to store metrics\ntrain_losses = []\ntrain_accuracies = []\n\nval_losses = []\nval_accuracies = []","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-12T19:03:03.789447Z","iopub.execute_input":"2024-12-12T19:03:03.790265Z","iopub.status.idle":"2024-12-12T19:03:03.796852Z","shell.execute_reply.started":"2024-12-12T19:03:03.790227Z","shell.execute_reply":"2024-12-12T19:03:03.795969Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"def compute_cosine_similarity(grad1, grad2):\n    \"\"\"\n    Computes the cosine similarity between two gradient dictionaries.\n    \n    Args:\n        grad1 (dict): Gradient dictionary 1.\n        grad2 (dict): Gradient dictionary 2.\n    \n    Returns:\n        float: Cosine similarity score.\n    \"\"\"\n    cosine_similarity = 0.0\n    num_valid_keys = 0  # To track valid gradient pairs\n\n    for key in grad1.keys():\n        g1, g2 = grad1[key], grad2[key]\n        \n        # Ensure both gradients are valid tensors\n        if g1 is not None and g2 is not None and g1.numel() > 0 and g2.numel() > 0:\n            dot_product = torch.sum(g1 * g2)\n            norm_g1 = torch.norm(g1)\n            norm_g2 = torch.norm(g2)\n\n            if norm_g1 > 0 and norm_g2 > 0:  # Avoid division by zero\n                cosine_similarity += (dot_product / (norm_g1 * norm_g2)).item()\n                num_valid_keys += 1\n\n    # Average cosine similarity over all valid keys\n    return cosine_similarity / num_valid_keys if num_valid_keys > 0 else 0.0","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-12T19:03:04.997475Z","iopub.execute_input":"2024-12-12T19:03:04.998058Z","iopub.status.idle":"2024-12-12T19:03:05.003881Z","shell.execute_reply.started":"2024-12-12T19:03:04.998024Z","shell.execute_reply":"2024-12-12T19:03:05.002989Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"from itertools import cycle\nteacher.to(params['device'])\nstudent.to(params['device'])\nfor epoch in range(num_epochs):\n    # Initialize metrics\n    epoch_train_loss, epoch_train_correct, total_train_samples = 0.0, 0, 0\n    epoch_val_loss, epoch_val_correct, total_val_samples = 0.0, 0, 0\n\n    teacher.train()\n    student.train()\n\n    mini_batch_counter = 0\n    n_batches = 10\n\n    # Iterate over labeled and unlabeled data\n    for (labeled_batch, unlabeled_batch) in zip(labeled_loader, cycle(unlabeled_loader)):\n        mini_batch_counter += 1\n\n        # Load labeled data\n        l_x, l_y = labeled_batch\n        l_x, l_y = l_x.to(params['device']), l_y.to(params['device'])\n\n        # Load unlabeled data\n        u_x = unlabeled_batch\n        u_x = u_x.to(params['device'])\n\n        # Zero gradients for both optimizers\n        t_optimizer.zero_grad()\n        s_optimizer.zero_grad()\n\n        # ----------------------------------\n        # Pseudo-labeling by Teacher\n        # ----------------------------------\n        y_u_pred_logits = teacher(u_x)\n        y_u_pred = torch.argmax(y_u_pred_logits.detach(), dim=1)\n\n        # ----------------------------------\n        # Student trains on pseudo-labeled data\n        # ----------------------------------\n        s_u_logits = student(u_x)\n        s_u_loss = F.cross_entropy(s_u_logits, y_u_pred)\n        s_u_loss.backward()\n\n        # Store gradients for unlabeled data\n        student_unlabeled_gradients = {\n            name: param.grad.clone() if param.grad is not None else None\n            for name, param in student.named_parameters()\n        }\n\n        s_optimizer.step()\n\n        # ----------------------------------\n        # Student trains on labeled data\n        # ----------------------------------\n        s_optimizer.zero_grad()\n        s_l_logits = student(l_x)\n        s_l_loss = F.cross_entropy(s_l_logits, l_y)\n        s_l_loss.backward()\n\n        # Store gradients for labeled data\n        student_labeled_gradients = {\n            name: param.grad.clone() if param.grad is not None else None\n            for name, param in student.named_parameters()\n        }\n\n        s_optimizer.zero_grad()\n\n        # Compute cosine similarity\n        h = compute_cosine_similarity(student_labeled_gradients, student_unlabeled_gradients)\n\n        # ----------------------------------\n        # Teacher meta-loss (MPL)\n        # ----------------------------------\n        t_l_logits = teacher(l_x)\n        t_l_loss = F.cross_entropy(t_l_logits, l_y)\n        t_mpl_loss = h * F.cross_entropy(y_u_pred_logits, y_u_pred)\n\n        (t_l_loss + t_mpl_loss).backward()\n        t_optimizer.step()\n\n        # Track training metrics\n        batch_train_loss = s_u_loss.item()\n        batch_train_accuracy = (torch.argmax(s_l_logits, dim=1) == l_y).float().mean().item()\n\n        epoch_train_loss += batch_train_loss * l_x.size(0)\n        epoch_train_correct += (torch.argmax(s_l_logits, dim=1) == l_y).sum().item()\n        total_train_samples += l_x.size(0)\n\n        # Print metrics every `n_batches`\n        if mini_batch_counter % n_batches == 0:\n            avg_batch_train_loss = epoch_train_loss / total_train_samples\n            avg_batch_train_accuracy = epoch_train_correct / total_train_samples\n\n            print(f'[Epoch {epoch+1}, Batch {mini_batch_counter}] '\n                  f'Batch Loss: {avg_batch_train_loss:.4f}, Batch Accuracy: {avg_batch_train_accuracy:.4f}')\n\n    # ----------------------------------\n    # Validation after each epoch\n    # ----------------------------------\n    teacher.eval()\n    student.eval()\n    with torch.no_grad():\n        for val_batch in val_loader:\n            val_x, val_y = val_batch\n            val_x, val_y = val_x.to(params['device']), val_y.to(params['device'])\n\n            val_logits = student(val_x)\n            val_loss = F.cross_entropy(val_logits, val_y)\n\n            epoch_val_loss += val_loss.item() * val_x.size(0)\n            epoch_val_correct += (torch.argmax(val_logits, dim=1) == val_y).sum().item()\n            total_val_samples += val_x.size(0)\n\n    # Average losses and accuracies\n    avg_train_loss = epoch_train_loss / total_train_samples\n    avg_train_accuracy = epoch_train_correct / total_train_samples\n    avg_val_loss = epoch_val_loss / total_val_samples\n    avg_val_accuracy = epoch_val_correct / total_val_samples\n\n    # Append metrics\n    train_losses.append(avg_train_loss)\n    train_accuracies.append(avg_train_accuracy)\n    val_losses.append(avg_val_loss)\n    val_accuracies.append(avg_val_accuracy)\n\n    # Print epoch summary\n    print(f'End of Epoch {epoch+1}/{num_epochs}, '\n          f'Train Loss: {avg_train_loss:.4f}, Train Accuracy: {avg_train_accuracy:.4f}, '\n          f'Val Loss: {avg_val_loss:.4f}, Val Accuracy: {avg_val_accuracy:.4f}')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-12T19:03:05.377714Z","iopub.execute_input":"2024-12-12T19:03:05.378004Z","iopub.status.idle":"2024-12-12T19:03:46.906670Z","shell.execute_reply.started":"2024-12-12T19:03:05.377978Z","shell.execute_reply":"2024-12-12T19:03:46.905451Z"}},"outputs":[{"name":"stdout","text":"[Epoch 1, Batch 10] Batch Loss: 1.8198, Batch Accuracy: 0.1187\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[17], line 82\u001b[0m\n\u001b[1;32m     79\u001b[0m t_optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     81\u001b[0m \u001b[38;5;66;03m# Track training metrics\u001b[39;00m\n\u001b[0;32m---> 82\u001b[0m batch_train_loss \u001b[38;5;241m=\u001b[39m \u001b[43ms_u_loss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     83\u001b[0m batch_train_accuracy \u001b[38;5;241m=\u001b[39m (torch\u001b[38;5;241m.\u001b[39margmax(s_l_logits, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m==\u001b[39m l_y)\u001b[38;5;241m.\u001b[39mfloat()\u001b[38;5;241m.\u001b[39mmean()\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m     85\u001b[0m epoch_train_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m batch_train_loss \u001b[38;5;241m*\u001b[39m l_x\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":17},{"cell_type":"code","source":"# model.qconfig=torch.quantization.get_default_qconfig('fbgemm')\n# model=torch.quantization.prepare_qat(model, inplace=True)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# QAT","metadata":{}},{"cell_type":"code","source":"%%capture capt\nteacher_quantized = torch.hub.load('facebookresearch/deit:main', 'deit_base_patch16_224', pretrained=True)\nteacher_quantized.qconfig = torch.quantization.get_default_qat_qconfig('fbgemm')\ntorch.quantization.prepare_qat(teacher_quantized, inplace=True)\n# teacher = teacher.cpu()\n# torch.quantization.convert(teacher, inplace=True)\n# print_size_of_model(teacher)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-12T19:10:29.253402Z","iopub.execute_input":"2024-12-12T19:10:29.253762Z","iopub.status.idle":"2024-12-12T19:10:31.823678Z","shell.execute_reply.started":"2024-12-12T19:10:29.253731Z","shell.execute_reply":"2024-12-12T19:10:31.822659Z"}},"outputs":[],"execution_count":30},{"cell_type":"code","source":"%%capture capt\nstudent_quantized = torch.hub.load('facebookresearch/deit:main', 'deit_base_patch16_224', pretrained=True)\nstudent_quantized.qconfig = torch.quantization.get_default_qat_qconfig('fbgemm')\ntorch.quantization.prepare_qat(student_quantized,inplace=True)\n# teacher = teacher.cpu()\n# torch.quantization.convert(teacher, inplace=True)\n# print_size_of_model(teacher)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-12T19:10:54.501302Z","iopub.execute_input":"2024-12-12T19:10:54.502048Z","iopub.status.idle":"2024-12-12T19:10:57.252242Z","shell.execute_reply.started":"2024-12-12T19:10:54.502012Z","shell.execute_reply":"2024-12-12T19:10:57.251526Z"}},"outputs":[],"execution_count":32},{"cell_type":"code","source":"num_epochs=params['epochs']\n# Optimizers\nt_optimizer = optim.SGD(teacher_quantized.parameters(), lr=0.001,momentum=0.9)\ns_optimizer = optim.SGD(student_quantized.parameters(), lr=0.001,momentum=0.9)\n\n# Lists to store metrics\ntrain_losses = []\ntrain_accuracies = []\nval_losses = []\nval_accuracies = []","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-12T19:11:03.595499Z","iopub.execute_input":"2024-12-12T19:11:03.595861Z","iopub.status.idle":"2024-12-12T19:11:03.603810Z","shell.execute_reply.started":"2024-12-12T19:11:03.595831Z","shell.execute_reply":"2024-12-12T19:11:03.602944Z"}},"outputs":[],"execution_count":33},{"cell_type":"code","source":"from itertools import cycle\nteacher_quantized.to(params['device'])\nstudent_quantized.to(params['device'])\nfor epoch in range(num_epochs):\n    # Initialize metrics\n    epoch_train_loss, epoch_train_correct, total_train_samples = 0.0, 0, 0\n    epoch_val_loss, epoch_val_correct, total_val_samples = 0.0, 0, 0\n\n    teacher.train()\n    student.train()\n\n    mini_batch_counter = 0\n    n_batches = 10\n\n    # Iterate over labeled and unlabeled data\n    for (labeled_batch, unlabeled_batch) in zip(labeled_loader, cycle(unlabeled_loader)):\n        mini_batch_counter += 1\n\n        # Load labeled data\n        l_x, l_y = labeled_batch\n        l_x, l_y = l_x.to(params['device']), l_y.to(params['device'])\n\n        # Load unlabeled data\n        u_x = unlabeled_batch\n        u_x = u_x.to(params['device'])\n\n        # Zero gradients for both optimizers\n        t_optimizer.zero_grad()\n        s_optimizer.zero_grad()\n\n        # ----------------------------------\n        # Pseudo-labeling by Teacher\n        # ----------------------------------\n        y_u_pred_logits = teacher_quantized(u_x)\n        y_u_pred = torch.argmax(y_u_pred_logits.detach(), dim=1)\n\n        # ----------------------------------\n        # Student trains on pseudo-labeled data\n        # ----------------------------------\n        s_u_logits = student_quantized(u_x)\n        s_u_loss = F.cross_entropy(s_u_logits, y_u_pred)\n        s_u_loss.backward()\n\n        # Store gradients for unlabeled data\n        student_unlabeled_gradients = {\n            name: param.grad.clone() if param.grad is not None else None\n            for name, param in student_quantized.named_parameters()\n        }\n\n        s_optimizer.step()\n\n        # ----------------------------------\n        # Student trains on labeled data\n        # ----------------------------------\n        s_optimizer.zero_grad()\n        s_l_logits = student_quantized(l_x)\n        s_l_loss = F.cross_entropy(s_l_logits, l_y)\n        s_l_loss.backward()\n\n        # Store gradients for labeled data\n        student_labeled_gradients = {\n            name: param.grad.clone() if param.grad is not None else None\n            for name, param in student_quantized.named_parameters()\n        }\n\n        s_optimizer.zero_grad()\n\n        # Compute cosine similarity\n        h = compute_cosine_similarity(student_labeled_gradients, student_unlabeled_gradients)\n\n        # ----------------------------------\n        # Teacher meta-loss (MPL)\n        # ----------------------------------\n        t_l_logits = teacher_quantized(l_x)\n        t_l_loss = F.cross_entropy(t_l_logits, l_y)\n        t_mpl_loss = h * F.cross_entropy(y_u_pred_logits, y_u_pred)\n\n        (t_l_loss + t_mpl_loss).backward()\n        t_optimizer.step()\n\n        # Track training metrics\n        batch_train_loss = s_u_loss.item()\n        batch_train_accuracy = (torch.argmax(s_l_logits, dim=1) == l_y).float().mean().item()\n\n        epoch_train_loss += batch_train_loss * l_x.size(0)\n        epoch_train_correct += (torch.argmax(s_l_logits, dim=1) == l_y).sum().item()\n        total_train_samples += l_x.size(0)\n\n        # Print metrics every `n_batches`\n        if mini_batch_counter % n_batches == 0:\n            avg_batch_train_loss = epoch_train_loss / total_train_samples\n            avg_batch_train_accuracy = epoch_train_correct / total_train_samples\n\n            print(f'[Epoch {epoch+1}, Batch {mini_batch_counter}] '\n                  f'Batch Loss: {avg_batch_train_loss:.4f}, Batch Accuracy: {avg_batch_train_accuracy:.4f}')\n\n    # ----------------------------------\n    # Validation after each epoch\n    # ----------------------------------\n    teacher.eval()\n    student.eval()\n    with torch.no_grad():\n        for val_batch in val_loader:\n            val_x, val_y = val_batch\n            val_x, val_y = val_x.to(params['device']), val_y.to(params['device'])\n\n            val_logits = student_quantized(val_x)\n            val_loss = F.cross_entropy(val_logits, val_y)\n\n            epoch_val_loss += val_loss.item() * val_x.size(0)\n            epoch_val_correct += (torch.argmax(val_logits, dim=1) == val_y).sum().item()\n            total_val_samples += val_x.size(0)\n\n    # Average losses and accuracies\n    avg_train_loss = epoch_train_loss / total_train_samples\n    avg_train_accuracy = epoch_train_correct / total_train_samples\n    avg_val_loss = epoch_val_loss / total_val_samples\n    avg_val_accuracy = epoch_val_correct / total_val_samples\n\n    # Append metrics\n    train_losses.append(avg_train_loss)\n    train_accuracies.append(avg_train_accuracy)\n    val_losses.append(avg_val_loss)\n    val_accuracies.append(avg_val_accuracy)\n\n    # Print epoch summary\n    print(f'End of Epoch {epoch+1}/{num_epochs}, '\n          f'Train Loss: {avg_train_loss:.4f}, Train Accuracy: {avg_train_accuracy:.4f}, '\n          f'Val Loss: {avg_val_loss:.4f}, Val Accuracy: {avg_val_accuracy:.4f}')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-12T19:11:05.753507Z","iopub.execute_input":"2024-12-12T19:11:05.754133Z","iopub.status.idle":"2024-12-12T19:49:13.753050Z","shell.execute_reply.started":"2024-12-12T19:11:05.754096Z","shell.execute_reply":"2024-12-12T19:49:13.751914Z"}},"outputs":[{"name":"stdout","text":"[Epoch 1, Batch 10] Batch Loss: 2.5368, Batch Accuracy: 0.0875\n[Epoch 1, Batch 20] Batch Loss: 3.0939, Batch Accuracy: 0.1437\n[Epoch 1, Batch 30] Batch Loss: 2.9490, Batch Accuracy: 0.1958\nEnd of Epoch 1/20, Train Loss: 2.8964, Train Accuracy: 0.2000, Val Loss: 2.6905, Val Accuracy: 0.3967\n[Epoch 2, Batch 10] Batch Loss: 1.6184, Batch Accuracy: 0.3875\n[Epoch 2, Batch 20] Batch Loss: 1.8269, Batch Accuracy: 0.3375\n[Epoch 2, Batch 30] Batch Loss: 1.8716, Batch Accuracy: 0.3500\nEnd of Epoch 2/20, Train Loss: 1.8417, Train Accuracy: 0.3480, Val Loss: 1.4932, Val Accuracy: 0.4389\n[Epoch 3, Batch 10] Batch Loss: 1.2907, Batch Accuracy: 0.4375\n[Epoch 3, Batch 20] Batch Loss: 1.3497, Batch Accuracy: 0.4562\n[Epoch 3, Batch 30] Batch Loss: 1.3294, Batch Accuracy: 0.4604\nEnd of Epoch 3/20, Train Loss: 1.3348, Train Accuracy: 0.4600, Val Loss: 1.2915, Val Accuracy: 0.5167\n[Epoch 4, Batch 10] Batch Loss: 0.9420, Batch Accuracy: 0.6500\n[Epoch 4, Batch 20] Batch Loss: 1.0395, Batch Accuracy: 0.6062\n[Epoch 4, Batch 30] Batch Loss: 1.0158, Batch Accuracy: 0.6062\nEnd of Epoch 4/20, Train Loss: 1.0084, Train Accuracy: 0.6120, Val Loss: 0.9744, Val Accuracy: 0.6533\n[Epoch 5, Batch 10] Batch Loss: 0.6971, Batch Accuracy: 0.6562\n[Epoch 5, Batch 20] Batch Loss: 0.6853, Batch Accuracy: 0.6969\n[Epoch 5, Batch 30] Batch Loss: 0.6498, Batch Accuracy: 0.6896\nEnd of Epoch 5/20, Train Loss: 0.6480, Train Accuracy: 0.6920, Val Loss: 0.7505, Val Accuracy: 0.7433\n[Epoch 6, Batch 10] Batch Loss: 0.4362, Batch Accuracy: 0.7875\n[Epoch 6, Batch 20] Batch Loss: 0.4609, Batch Accuracy: 0.8031\n[Epoch 6, Batch 30] Batch Loss: 0.4529, Batch Accuracy: 0.7917\nEnd of Epoch 6/20, Train Loss: 0.4458, Train Accuracy: 0.7900, Val Loss: 0.4758, Val Accuracy: 0.8244\n[Epoch 7, Batch 10] Batch Loss: 0.2850, Batch Accuracy: 0.7625\n[Epoch 7, Batch 20] Batch Loss: 0.3012, Batch Accuracy: 0.8094\n[Epoch 7, Batch 30] Batch Loss: 0.3501, Batch Accuracy: 0.8063\nEnd of Epoch 7/20, Train Loss: 0.3443, Train Accuracy: 0.8120, Val Loss: 0.5630, Val Accuracy: 0.8089\n[Epoch 8, Batch 10] Batch Loss: 0.1899, Batch Accuracy: 0.7875\n[Epoch 8, Batch 20] Batch Loss: 0.2422, Batch Accuracy: 0.8063\n[Epoch 8, Batch 30] Batch Loss: 0.3125, Batch Accuracy: 0.8167\nEnd of Epoch 8/20, Train Loss: 0.3090, Train Accuracy: 0.8200, Val Loss: 0.6870, Val Accuracy: 0.7978\n[Epoch 9, Batch 10] Batch Loss: 0.2848, Batch Accuracy: 0.8250\n[Epoch 9, Batch 20] Batch Loss: 0.3362, Batch Accuracy: 0.8219\n[Epoch 9, Batch 30] Batch Loss: 0.3339, Batch Accuracy: 0.8187\nEnd of Epoch 9/20, Train Loss: 0.3348, Train Accuracy: 0.8180, Val Loss: 0.4247, Val Accuracy: 0.8422\n[Epoch 10, Batch 10] Batch Loss: 0.4389, Batch Accuracy: 0.8375\n[Epoch 10, Batch 20] Batch Loss: 0.5097, Batch Accuracy: 0.7969\n[Epoch 10, Batch 30] Batch Loss: 0.5610, Batch Accuracy: 0.7833\nEnd of Epoch 10/20, Train Loss: 0.5495, Train Accuracy: 0.7820, Val Loss: 0.5300, Val Accuracy: 0.8233\n[Epoch 11, Batch 10] Batch Loss: 0.2585, Batch Accuracy: 0.8313\n[Epoch 11, Batch 20] Batch Loss: 0.2438, Batch Accuracy: 0.8531\n[Epoch 11, Batch 30] Batch Loss: 0.2392, Batch Accuracy: 0.8458\nEnd of Epoch 11/20, Train Loss: 0.2353, Train Accuracy: 0.8460, Val Loss: 0.5836, Val Accuracy: 0.8167\n[Epoch 12, Batch 10] Batch Loss: 0.3602, Batch Accuracy: 0.8625\n[Epoch 12, Batch 20] Batch Loss: 0.3995, Batch Accuracy: 0.8719\n[Epoch 12, Batch 30] Batch Loss: 0.4224, Batch Accuracy: 0.8562\nEnd of Epoch 12/20, Train Loss: 0.4143, Train Accuracy: 0.8540, Val Loss: 0.5980, Val Accuracy: 0.8133\n[Epoch 13, Batch 10] Batch Loss: 0.1498, Batch Accuracy: 0.8125\n[Epoch 13, Batch 20] Batch Loss: 0.2586, Batch Accuracy: 0.8500\n[Epoch 13, Batch 30] Batch Loss: 0.2878, Batch Accuracy: 0.8542\nEnd of Epoch 13/20, Train Loss: 0.3132, Train Accuracy: 0.8560, Val Loss: 0.4623, Val Accuracy: 0.8489\n[Epoch 14, Batch 10] Batch Loss: 0.5933, Batch Accuracy: 0.7750\n[Epoch 14, Batch 20] Batch Loss: 0.5720, Batch Accuracy: 0.8250\n[Epoch 14, Batch 30] Batch Loss: 0.5257, Batch Accuracy: 0.8104\nEnd of Epoch 14/20, Train Loss: 0.5111, Train Accuracy: 0.8140, Val Loss: 0.3902, Val Accuracy: 0.8689\n[Epoch 15, Batch 10] Batch Loss: 0.2271, Batch Accuracy: 0.8875\n[Epoch 15, Batch 20] Batch Loss: 0.2308, Batch Accuracy: 0.8562\n[Epoch 15, Batch 30] Batch Loss: 0.2150, Batch Accuracy: 0.8708\nEnd of Epoch 15/20, Train Loss: 0.2119, Train Accuracy: 0.8680, Val Loss: 0.4258, Val Accuracy: 0.8478\n[Epoch 16, Batch 10] Batch Loss: 0.1099, Batch Accuracy: 0.8313\n[Epoch 16, Batch 20] Batch Loss: 0.1036, Batch Accuracy: 0.8719\n[Epoch 16, Batch 30] Batch Loss: 0.1108, Batch Accuracy: 0.8958\nEnd of Epoch 16/20, Train Loss: 0.1090, Train Accuracy: 0.8980, Val Loss: 0.4049, Val Accuracy: 0.8733\n[Epoch 17, Batch 10] Batch Loss: 0.1028, Batch Accuracy: 0.8938\n[Epoch 17, Batch 20] Batch Loss: 0.0979, Batch Accuracy: 0.8906\n[Epoch 17, Batch 30] Batch Loss: 0.0929, Batch Accuracy: 0.8896\nEnd of Epoch 17/20, Train Loss: 0.0905, Train Accuracy: 0.8900, Val Loss: 0.4135, Val Accuracy: 0.8778\n[Epoch 18, Batch 10] Batch Loss: 0.0779, Batch Accuracy: 0.9250\n[Epoch 18, Batch 20] Batch Loss: 0.0851, Batch Accuracy: 0.8969\n[Epoch 18, Batch 30] Batch Loss: 0.0918, Batch Accuracy: 0.8917\nEnd of Epoch 18/20, Train Loss: 0.0891, Train Accuracy: 0.8880, Val Loss: 0.5050, Val Accuracy: 0.8600\n[Epoch 19, Batch 10] Batch Loss: 0.0693, Batch Accuracy: 0.8875\n[Epoch 19, Batch 20] Batch Loss: 0.0815, Batch Accuracy: 0.8719\n[Epoch 19, Batch 30] Batch Loss: 0.0750, Batch Accuracy: 0.8875\nEnd of Epoch 19/20, Train Loss: 0.0733, Train Accuracy: 0.8900, Val Loss: 0.4756, Val Accuracy: 0.8644\n[Epoch 20, Batch 10] Batch Loss: 0.0978, Batch Accuracy: 0.8500\n[Epoch 20, Batch 20] Batch Loss: 0.0745, Batch Accuracy: 0.8688\n[Epoch 20, Batch 30] Batch Loss: 0.0758, Batch Accuracy: 0.8792\nEnd of Epoch 20/20, Train Loss: 0.0738, Train Accuracy: 0.8840, Val Loss: 0.4044, Val Accuracy: 0.8833\n","output_type":"stream"}],"execution_count":34},{"cell_type":"code","source":"def print_size_of_model(model):\n    \"\"\" Prints the real size of the model \"\"\"\n    torch.save(model.state_dict(), \"temp.p\")\n    print('Size (MB):', os.path.getsize(\"temp.p\")/1e6)\n    os.remove('temp.p')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-12T20:07:15.548652Z","iopub.execute_input":"2024-12-12T20:07:15.549038Z","iopub.status.idle":"2024-12-12T20:07:15.553840Z","shell.execute_reply.started":"2024-12-12T20:07:15.549008Z","shell.execute_reply":"2024-12-12T20:07:15.552889Z"}},"outputs":[],"execution_count":37},{"cell_type":"code","source":"teacher_quantized = teacher_quantized.cpu()\ntorch.quantization.convert(teacher_quantized, inplace=True)\nprint_size_of_model(teacher_quantized)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-12T20:19:54.220484Z","iopub.execute_input":"2024-12-12T20:19:54.221346Z","iopub.status.idle":"2024-12-12T20:19:57.046837Z","shell.execute_reply.started":"2024-12-12T20:19:54.221307Z","shell.execute_reply":"2024-12-12T20:19:57.045878Z"}},"outputs":[{"name":"stdout","text":"Size (MB): 88.862924\n","output_type":"stream"}],"execution_count":52},{"cell_type":"code","source":"torch.save(teacher_quantized.state_dict(),\"teacher_quantized_model.pt\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-12T20:20:17.983561Z","iopub.execute_input":"2024-12-12T20:20:17.983928Z","iopub.status.idle":"2024-12-12T20:20:18.520195Z","shell.execute_reply.started":"2024-12-12T20:20:17.983895Z","shell.execute_reply":"2024-12-12T20:20:18.519456Z"}},"outputs":[],"execution_count":53},{"cell_type":"code","source":"teacher = torch.hub.load('facebookresearch/deit:main', 'deit_base_patch16_224', pretrained=True)\nteacher.qconfig = torch.quantization.get_default_qat_qconfig('fbgemm')\ntorch.quantization.prepare_qat(teacher, inplace=True)\ntorch.quantization.convert(teacher,inplace=True)\nteacher.load_state_dict(torch.load(\"teacher_quantized_model.pt\"))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-12T20:21:41.779075Z","iopub.execute_input":"2024-12-12T20:21:41.779421Z","iopub.status.idle":"2024-12-12T20:21:47.389831Z","shell.execute_reply.started":"2024-12-12T20:21:41.779388Z","shell.execute_reply":"2024-12-12T20:21:47.388985Z"}},"outputs":[{"name":"stderr","text":"Using cache found in /root/.cache/torch/hub/facebookresearch_deit_main\n/tmp/ipykernel_23/3932794387.py:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  teacher.load_state_dict(torch.load(\"teacher_quantized_model.pt\"))\n","output_type":"stream"},{"execution_count":57,"output_type":"execute_result","data":{"text/plain":"<All keys matched successfully>"},"metadata":{}}],"execution_count":57},{"cell_type":"code","source":"teacher.to('cpu')\nteacher.train()\nfor img,label in val_loader:\n    img=img.cpu()\n    label=label.cpu()\n    out=teacher(img)\n    break","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-12T20:23:15.452314Z","iopub.execute_input":"2024-12-12T20:23:15.452646Z","iopub.status.idle":"2024-12-12T20:23:15.640839Z","shell.execute_reply.started":"2024-12-12T20:23:15.452617Z","shell.execute_reply":"2024-12-12T20:23:15.639259Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)","Cell \u001b[0;32mIn[60], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m img\u001b[38;5;241m=\u001b[39mimg\u001b[38;5;241m.\u001b[39mcpu()\n\u001b[1;32m      5\u001b[0m label\u001b[38;5;241m=\u001b[39mlabel\u001b[38;5;241m.\u001b[39mcpu()\n\u001b[0;32m----> 6\u001b[0m out\u001b[38;5;241m=\u001b[39m\u001b[43mteacher\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mbreak\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/timm/models/vision_transformer.py:829\u001b[0m, in \u001b[0;36mVisionTransformer.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    828\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[0;32m--> 829\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    830\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforward_head(x)\n\u001b[1;32m    831\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/timm/models/vision_transformer.py:803\u001b[0m, in \u001b[0;36mVisionTransformer.forward_features\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    802\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward_features\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[0;32m--> 803\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpatch_embed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    804\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pos_embed(x)\n\u001b[1;32m    805\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpatch_drop(x)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/timm/layers/patch_embed.py:131\u001b[0m, in \u001b[0;36mPatchEmbed.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    129\u001b[0m     pad_w \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpatch_size[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m-\u001b[39m W \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpatch_size[\u001b[38;5;241m1\u001b[39m]) \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpatch_size[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    130\u001b[0m     x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mpad(x, (\u001b[38;5;241m0\u001b[39m, pad_w, \u001b[38;5;241m0\u001b[39m, pad_h))\n\u001b[0;32m--> 131\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mproj\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mflatten:\n\u001b[1;32m    133\u001b[0m     x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mflatten(\u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m)  \u001b[38;5;66;03m# NCHW -> NLC\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/ao/nn/quantized/modules/conv.py:469\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    466\u001b[0m     _reversed_padding_repeated_twice \u001b[38;5;241m=\u001b[39m _reverse_repeat_padding(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding)\n\u001b[1;32m    467\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, _reversed_padding_repeated_twice,\n\u001b[1;32m    468\u001b[0m                   mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode)\n\u001b[0;32m--> 469\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquantized\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    470\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_packed_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscale\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzero_point\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/_ops.py:1061\u001b[0m, in \u001b[0;36mOpOverloadPacket.__call__\u001b[0;34m(self_, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1059\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m self_\u001b[38;5;241m.\u001b[39m_has_torchbind_op_overload \u001b[38;5;129;01mand\u001b[39;00m _must_dispatch_in_python(args, kwargs):\n\u001b[1;32m   1060\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _call_overload_packet_from_python(self_, args, kwargs)\n\u001b[0;32m-> 1061\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mself_\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_op\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n","\u001b[0;31mNotImplementedError\u001b[0m: Could not run 'quantized::conv2d.new' with arguments from the 'CPU' backend. This could be because the operator doesn't exist for this backend, or was omitted during the selective/custom build process (if using custom build). If you are a Facebook employee using PyTorch on mobile, please visit https://fburl.com/ptmfixes for possible resolutions. 'quantized::conv2d.new' is only available for these backends: [Meta, QuantizedCPU, QuantizedCUDA, BackendSelect, Python, FuncTorchDynamicLayerBackMode, Functionalize, Named, Conjugate, Negative, ZeroTensor, ADInplaceOrView, AutogradOther, AutogradCPU, AutogradCUDA, AutogradXLA, AutogradMPS, AutogradXPU, AutogradHPU, AutogradLazy, AutogradMeta, Tracer, AutocastCPU, AutocastXPU, AutocastCUDA, FuncTorchBatched, BatchedNestedTensor, FuncTorchVmapMode, Batched, VmapMode, FuncTorchGradWrapper, PythonTLSSnapshot, FuncTorchDynamicLayerFrontMode, PreDispatch, PythonDispatcher].\n\nMeta: registered at /usr/local/src/pytorch/aten/src/ATen/core/MetaFallbackKernel.cpp:23 [backend fallback]\nQuantizedCPU: registered at /usr/local/src/pytorch/aten/src/ATen/native/quantized/cpu/qconv.cpp:1970 [kernel]\nQuantizedCUDA: registered at /usr/local/src/pytorch/aten/src/ATen/native/quantized/cudnn/Conv.cpp:391 [kernel]\nBackendSelect: fallthrough registered at /usr/local/src/pytorch/aten/src/ATen/core/BackendSelectFallbackKernel.cpp:3 [backend fallback]\nPython: registered at /usr/local/src/pytorch/aten/src/ATen/core/PythonFallbackKernel.cpp:153 [backend fallback]\nFuncTorchDynamicLayerBackMode: registered at /usr/local/src/pytorch/aten/src/ATen/functorch/DynamicLayer.cpp:497 [backend fallback]\nFunctionalize: registered at /usr/local/src/pytorch/aten/src/ATen/FunctionalizeFallbackKernel.cpp:349 [backend fallback]\nNamed: registered at /usr/local/src/pytorch/aten/src/ATen/core/NamedRegistrations.cpp:7 [backend fallback]\nConjugate: registered at /usr/local/src/pytorch/aten/src/ATen/ConjugateFallback.cpp:17 [backend fallback]\nNegative: registered at /usr/local/src/pytorch/aten/src/ATen/native/NegateFallback.cpp:18 [backend fallback]\nZeroTensor: registered at /usr/local/src/pytorch/aten/src/ATen/ZeroTensorFallback.cpp:86 [backend fallback]\nADInplaceOrView: fallthrough registered at /usr/local/src/pytorch/aten/src/ATen/core/VariableFallbackKernel.cpp:86 [backend fallback]\nAutogradOther: registered at /usr/local/src/pytorch/aten/src/ATen/core/VariableFallbackKernel.cpp:53 [backend fallback]\nAutogradCPU: registered at /usr/local/src/pytorch/aten/src/ATen/core/VariableFallbackKernel.cpp:57 [backend fallback]\nAutogradCUDA: registered at /usr/local/src/pytorch/aten/src/ATen/core/VariableFallbackKernel.cpp:65 [backend fallback]\nAutogradXLA: registered at /usr/local/src/pytorch/aten/src/ATen/core/VariableFallbackKernel.cpp:69 [backend fallback]\nAutogradMPS: registered at /usr/local/src/pytorch/aten/src/ATen/core/VariableFallbackKernel.cpp:77 [backend fallback]\nAutogradXPU: registered at /usr/local/src/pytorch/aten/src/ATen/core/VariableFallbackKernel.cpp:61 [backend fallback]\nAutogradHPU: registered at /usr/local/src/pytorch/aten/src/ATen/core/VariableFallbackKernel.cpp:90 [backend fallback]\nAutogradLazy: registered at /usr/local/src/pytorch/aten/src/ATen/core/VariableFallbackKernel.cpp:73 [backend fallback]\nAutogradMeta: registered at /usr/local/src/pytorch/aten/src/ATen/core/VariableFallbackKernel.cpp:81 [backend fallback]\nTracer: registered at /usr/local/src/pytorch/torch/csrc/autograd/TraceTypeManual.cpp:297 [backend fallback]\nAutocastCPU: fallthrough registered at /usr/local/src/pytorch/aten/src/ATen/autocast_mode.cpp:209 [backend fallback]\nAutocastXPU: fallthrough registered at /usr/local/src/pytorch/aten/src/ATen/autocast_mode.cpp:351 [backend fallback]\nAutocastCUDA: fallthrough registered at /usr/local/src/pytorch/aten/src/ATen/autocast_mode.cpp:165 [backend fallback]\nFuncTorchBatched: registered at /usr/local/src/pytorch/aten/src/ATen/functorch/LegacyBatchingRegistrations.cpp:731 [backend fallback]\nBatchedNestedTensor: registered at /usr/local/src/pytorch/aten/src/ATen/functorch/LegacyBatchingRegistrations.cpp:758 [backend fallback]\nFuncTorchVmapMode: fallthrough registered at /usr/local/src/pytorch/aten/src/ATen/functorch/VmapModeRegistrations.cpp:27 [backend fallback]\nBatched: registered at /usr/local/src/pytorch/aten/src/ATen/LegacyBatchingRegistrations.cpp:1075 [backend fallback]\nVmapMode: fallthrough registered at /usr/local/src/pytorch/aten/src/ATen/VmapModeRegistrations.cpp:33 [backend fallback]\nFuncTorchGradWrapper: registered at /usr/local/src/pytorch/aten/src/ATen/functorch/TensorWrapper.cpp:207 [backend fallback]\nPythonTLSSnapshot: registered at /usr/local/src/pytorch/aten/src/ATen/core/PythonFallbackKernel.cpp:161 [backend fallback]\nFuncTorchDynamicLayerFrontMode: registered at /usr/local/src/pytorch/aten/src/ATen/functorch/DynamicLayer.cpp:493 [backend fallback]\nPreDispatch: registered at /usr/local/src/pytorch/aten/src/ATen/core/PythonFallbackKernel.cpp:165 [backend fallback]\nPythonDispatcher: registered at /usr/local/src/pytorch/aten/src/ATen/core/PythonFallbackKernel.cpp:157 [backend fallback]\n"],"ename":"NotImplementedError","evalue":"Could not run 'quantized::conv2d.new' with arguments from the 'CPU' backend. This could be because the operator doesn't exist for this backend, or was omitted during the selective/custom build process (if using custom build). If you are a Facebook employee using PyTorch on mobile, please visit https://fburl.com/ptmfixes for possible resolutions. 'quantized::conv2d.new' is only available for these backends: [Meta, QuantizedCPU, QuantizedCUDA, BackendSelect, Python, FuncTorchDynamicLayerBackMode, Functionalize, Named, Conjugate, Negative, ZeroTensor, ADInplaceOrView, AutogradOther, AutogradCPU, AutogradCUDA, AutogradXLA, AutogradMPS, AutogradXPU, AutogradHPU, AutogradLazy, AutogradMeta, Tracer, AutocastCPU, AutocastXPU, AutocastCUDA, FuncTorchBatched, BatchedNestedTensor, FuncTorchVmapMode, Batched, VmapMode, FuncTorchGradWrapper, PythonTLSSnapshot, FuncTorchDynamicLayerFrontMode, PreDispatch, PythonDispatcher].\n\nMeta: registered at /usr/local/src/pytorch/aten/src/ATen/core/MetaFallbackKernel.cpp:23 [backend fallback]\nQuantizedCPU: registered at /usr/local/src/pytorch/aten/src/ATen/native/quantized/cpu/qconv.cpp:1970 [kernel]\nQuantizedCUDA: registered at /usr/local/src/pytorch/aten/src/ATen/native/quantized/cudnn/Conv.cpp:391 [kernel]\nBackendSelect: fallthrough registered at /usr/local/src/pytorch/aten/src/ATen/core/BackendSelectFallbackKernel.cpp:3 [backend fallback]\nPython: registered at /usr/local/src/pytorch/aten/src/ATen/core/PythonFallbackKernel.cpp:153 [backend fallback]\nFuncTorchDynamicLayerBackMode: registered at /usr/local/src/pytorch/aten/src/ATen/functorch/DynamicLayer.cpp:497 [backend fallback]\nFunctionalize: registered at /usr/local/src/pytorch/aten/src/ATen/FunctionalizeFallbackKernel.cpp:349 [backend fallback]\nNamed: registered at /usr/local/src/pytorch/aten/src/ATen/core/NamedRegistrations.cpp:7 [backend fallback]\nConjugate: registered at /usr/local/src/pytorch/aten/src/ATen/ConjugateFallback.cpp:17 [backend fallback]\nNegative: registered at /usr/local/src/pytorch/aten/src/ATen/native/NegateFallback.cpp:18 [backend fallback]\nZeroTensor: registered at /usr/local/src/pytorch/aten/src/ATen/ZeroTensorFallback.cpp:86 [backend fallback]\nADInplaceOrView: fallthrough registered at /usr/local/src/pytorch/aten/src/ATen/core/VariableFallbackKernel.cpp:86 [backend fallback]\nAutogradOther: registered at /usr/local/src/pytorch/aten/src/ATen/core/VariableFallbackKernel.cpp:53 [backend fallback]\nAutogradCPU: registered at /usr/local/src/pytorch/aten/src/ATen/core/VariableFallbackKernel.cpp:57 [backend fallback]\nAutogradCUDA: registered at /usr/local/src/pytorch/aten/src/ATen/core/VariableFallbackKernel.cpp:65 [backend fallback]\nAutogradXLA: registered at /usr/local/src/pytorch/aten/src/ATen/core/VariableFallbackKernel.cpp:69 [backend fallback]\nAutogradMPS: registered at /usr/local/src/pytorch/aten/src/ATen/core/VariableFallbackKernel.cpp:77 [backend fallback]\nAutogradXPU: registered at /usr/local/src/pytorch/aten/src/ATen/core/VariableFallbackKernel.cpp:61 [backend fallback]\nAutogradHPU: registered at /usr/local/src/pytorch/aten/src/ATen/core/VariableFallbackKernel.cpp:90 [backend fallback]\nAutogradLazy: registered at /usr/local/src/pytorch/aten/src/ATen/core/VariableFallbackKernel.cpp:73 [backend fallback]\nAutogradMeta: registered at /usr/local/src/pytorch/aten/src/ATen/core/VariableFallbackKernel.cpp:81 [backend fallback]\nTracer: registered at /usr/local/src/pytorch/torch/csrc/autograd/TraceTypeManual.cpp:297 [backend fallback]\nAutocastCPU: fallthrough registered at /usr/local/src/pytorch/aten/src/ATen/autocast_mode.cpp:209 [backend fallback]\nAutocastXPU: fallthrough registered at /usr/local/src/pytorch/aten/src/ATen/autocast_mode.cpp:351 [backend fallback]\nAutocastCUDA: fallthrough registered at /usr/local/src/pytorch/aten/src/ATen/autocast_mode.cpp:165 [backend fallback]\nFuncTorchBatched: registered at /usr/local/src/pytorch/aten/src/ATen/functorch/LegacyBatchingRegistrations.cpp:731 [backend fallback]\nBatchedNestedTensor: registered at /usr/local/src/pytorch/aten/src/ATen/functorch/LegacyBatchingRegistrations.cpp:758 [backend fallback]\nFuncTorchVmapMode: fallthrough registered at /usr/local/src/pytorch/aten/src/ATen/functorch/VmapModeRegistrations.cpp:27 [backend fallback]\nBatched: registered at /usr/local/src/pytorch/aten/src/ATen/LegacyBatchingRegistrations.cpp:1075 [backend fallback]\nVmapMode: fallthrough registered at /usr/local/src/pytorch/aten/src/ATen/VmapModeRegistrations.cpp:33 [backend fallback]\nFuncTorchGradWrapper: registered at /usr/local/src/pytorch/aten/src/ATen/functorch/TensorWrapper.cpp:207 [backend fallback]\nPythonTLSSnapshot: registered at /usr/local/src/pytorch/aten/src/ATen/core/PythonFallbackKernel.cpp:161 [backend fallback]\nFuncTorchDynamicLayerFrontMode: registered at /usr/local/src/pytorch/aten/src/ATen/functorch/DynamicLayer.cpp:493 [backend fallback]\nPreDispatch: registered at /usr/local/src/pytorch/aten/src/ATen/core/PythonFallbackKernel.cpp:165 [backend fallback]\nPythonDispatcher: registered at /usr/local/src/pytorch/aten/src/ATen/core/PythonFallbackKernel.cpp:157 [backend fallback]\n","output_type":"error"}],"execution_count":60},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print_size_of_model(teacher)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-12T20:19:28.392171Z","iopub.execute_input":"2024-12-12T20:19:28.393020Z","iopub.status.idle":"2024-12-12T20:19:28.980584Z","shell.execute_reply.started":"2024-12-12T20:19:28.392969Z","shell.execute_reply":"2024-12-12T20:19:28.979668Z"}},"outputs":[{"name":"stdout","text":"Size (MB): 347.976818\n","output_type":"stream"}],"execution_count":51},{"cell_type":"code","source":"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-12T20:19:09.043950Z","iopub.execute_input":"2024-12-12T20:19:09.044318Z","iopub.status.idle":"2024-12-12T20:19:09.970554Z","shell.execute_reply.started":"2024-12-12T20:19:09.044277Z","shell.execute_reply":"2024-12-12T20:19:09.969466Z"}},"outputs":[],"execution_count":48},{"cell_type":"code","source":"model=torch.load_state_dict('/kaggle/working/teacher_quantized_model.pt')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-12T20:09:29.826408Z","iopub.execute_input":"2024-12-12T20:09:29.827382Z","iopub.status.idle":"2024-12-12T20:09:30.101227Z","shell.execute_reply.started":"2024-12-12T20:09:29.827330Z","shell.execute_reply":"2024-12-12T20:09:30.100479Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_23/1427919192.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  model=torch.load('/kaggle/working/teacher_quantized_model.pt')\n","output_type":"stream"}],"execution_count":41},{"cell_type":"code","source":"student=student.cpu()\ntorch.quantization.convert(student,inplace=True)\nprint_size_of_model(student)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-05T09:59:16.984533Z","iopub.execute_input":"2024-12-05T09:59:16.985590Z","iopub.status.idle":"2024-12-05T09:59:19.304365Z","shell.execute_reply.started":"2024-12-05T09:59:16.985549Z","shell.execute_reply":"2024-12-05T09:59:19.303366Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import DataLoader\ncriterion=nn.CrossEntropyLoss()\ndef evaluate_model(model, val_loader, criterion, device='cpu'):\n    \"\"\"\n    Evaluate the model on a validation dataset.\n    \n    Args:\n    - model: The PyTorch model to evaluate.\n    - val_loader: DataLoader for the validation dataset.\n    - criterion: The loss function.\n    - device: The device to run the evaluation on ('cpu' or 'cuda').\n    \n    Returns:\n    - avg_loss: Average loss across the validation set.\n    - accuracy: Accuracy across the validation set.\n    \"\"\"\n    model.eval()  # Set model to evaluation mode\n    total_loss = 0.0\n    correct_predictions = 0\n    total_samples = 0\n\n    with torch.no_grad():  # No need to compute gradients\n        for inputs, labels in val_loader:\n            inputs, labels = inputs.to(device), labels.to(device)\n            \n            # Forward pass\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            total_loss += loss.item() * inputs.size(0)  # Accumulate loss\n            \n            # Calculate accuracy\n            _, predicted = torch.max(outputs, 1)  # Get class predictions\n            correct_predictions += (predicted == labels).sum().item()\n            total_samples += labels.size(0)\n\n    # Compute average loss and accuracy\n    avg_loss = total_loss / total_samples\n    accuracy = correct_predictions / total_samples\n\n    return avg_loss, accuracy\n\n# Example usage\n# Assuming val_loader, model, and criterion are defined\n# Move the model to device\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmodel.to(device)\n\navg_loss, accuracy = evaluate_model(model, val_loader, criterion, device)\nprint(f\"Validation Loss: {avg_loss:.4f}, Validation Accuracy: {accuracy:.2%}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-05T10:08:27.299805Z","iopub.execute_input":"2024-12-05T10:08:27.300655Z","iopub.status.idle":"2024-12-05T10:08:27.453691Z","shell.execute_reply.started":"2024-12-05T10:08:27.300621Z","shell.execute_reply":"2024-12-05T10:08:27.452246Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-05T10:08:35.546540Z","iopub.execute_input":"2024-12-05T10:08:35.547248Z","iopub.status.idle":"2024-12-05T10:08:35.733997Z","shell.execute_reply.started":"2024-12-05T10:08:35.547213Z","shell.execute_reply":"2024-12-05T10:08:35.733240Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"teacher","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-05T10:08:44.281250Z","iopub.execute_input":"2024-12-05T10:08:44.282046Z","iopub.status.idle":"2024-12-05T10:08:44.521715Z","shell.execute_reply.started":"2024-12-05T10:08:44.282010Z","shell.execute_reply":"2024-12-05T10:08:44.520873Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}